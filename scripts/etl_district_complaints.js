import mongoose from 'mongoose';
import dotenv from 'dotenv';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import csv from 'csv-parser';
import XLSX from 'xlsx';
import SignalHuman from '../models/SignalHuman.js';
import { connectDB } from '../config/database.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

dotenv.config();

// êµ¬ ì´ë¦„ -> êµ¬ ì½”ë“œ ë§¤í•‘
const DISTRICT_CODE_MAP = {
  'ì¢…ë¡œêµ¬': '11110',
  'ì¤‘êµ¬': '11140',
  'ìš©ì‚°êµ¬': '11170',
  'ì„±ë™êµ¬': '11200',
  'ê´‘ì§„êµ¬': '11215',
  'ë™ëŒ€ë¬¸êµ¬': '11230',
  'ì¤‘ë‘êµ¬': '11260',
  'ì„±ë¶êµ¬': '11290',
  'ê°•ë¶êµ¬': '11305',
  'ë„ë´‰êµ¬': '11320',
  'ë…¸ì›êµ¬': '11350',
  'ì€í‰êµ¬': '11380',
  'ì„œëŒ€ë¬¸êµ¬': '11410',
  'ë§ˆí¬êµ¬': '11440',
  'ì–‘ì²œêµ¬': '11470',
  'ê°•ì„œêµ¬': '11500',
  'êµ¬ë¡œêµ¬': '11530',
  'ê¸ˆì²œêµ¬': '11545',
  'ì˜ë“±í¬êµ¬': '11560',
  'ë™ì‘êµ¬': '11590',
  'ê´€ì•…êµ¬': '11620',
  'ì„œì´ˆêµ¬': '11650',
  'ê°•ë‚¨êµ¬': '11680',
  'ì†¡íŒŒêµ¬': '11710',
  'ê°•ë™êµ¬': '11740'
};

/**
 * CSV íŒŒì¼ ì²˜ë¦¬
 */
async function processCSV(filePath) {
  console.log(`\nğŸ“¥ Processing CSV: ${path.basename(filePath)}`);

  const rows = [];
  let rowCount = 0;

  // CP949 ì¸ì½”ë”© ì§€ì›ì„ ìœ„í•´ iconv-lite ì‚¬ìš©
  let iconv;
  try {
    iconv = (await import('iconv-lite')).default;
  } catch (e) {
    // iconv-liteê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì¸ì½”ë”© ì‚¬ìš©
    iconv = null;
  }

  return new Promise((resolve, reject) => {
    const stream = fs.createReadStream(filePath);
    
    // ì¸ì½”ë”© ë³€í™˜ ìŠ¤íŠ¸ë¦¼ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
    let csvStream;
    if (iconv) {
      const iconvStream = iconv.decodeStream('cp949');
      csvStream = stream.pipe(iconvStream).pipe(csv());
    } else {
      // UTF-8ë¡œ ì‹œë„
      csvStream = stream.pipe(csv());
    }

    csvStream
      .on('data', (row) => {
        rows.push(row);
        rowCount++;
      })
      .on('end', async () => {
        console.log(`  Total rows: ${rowCount}`);
        try {
          const operations = await parseRows(rows, filePath);
          resolve(operations);
        } catch (error) {
          reject(error);
        }
      })
      .on('error', (error) => {
        // CP949 ì‹¤íŒ¨ ì‹œ UTF-8ë¡œ ì¬ì‹œë„
        if (iconv && !error.message.includes('UTF')) {
          console.log(`  âš ï¸  CP949 decode failed, retrying with UTF-8...`);
          fs.createReadStream(filePath, { encoding: 'utf8' })
            .pipe(csv())
            .on('data', (row) => {
              if (!rows.find(r => JSON.stringify(r) === JSON.stringify(row))) {
                rows.push(row);
                rowCount++;
              }
            })
            .on('end', async () => {
              console.log(`  Total rows (retry): ${rowCount}`);
              try {
                const operations = await parseRows(rows, filePath);
                resolve(operations);
              } catch (err) {
                reject(err);
              }
            })
            .on('error', reject);
        } else {
          reject(error);
        }
      });
  });
}

/**
 * XLSX íŒŒì¼ ì²˜ë¦¬
 */
async function processXLSX(filePath) {
  console.log(`\nğŸ“¥ Processing XLSX: ${path.basename(filePath)}`);

  const workbook = XLSX.readFile(filePath);
  const sheetName = workbook.SheetNames[0];
  const worksheet = workbook.Sheets[sheetName];
  const rows = XLSX.utils.sheet_to_json(worksheet, { defval: '' });

  console.log(`  Total rows: ${rows.length}`);
  const operations = await parseRows(rows, filePath);
  return operations;
}

/**
 * í–‰ ë°ì´í„° íŒŒì‹±í•˜ì—¬ MongoDB operations ìƒì„±
 */
async function parseRows(rows, filePath) {
  const operations = [];
  let processedCount = 0;

  for (const row of rows) {
    // ë…„ë„, ì›” ì¶”ì¶œ - ë‹¤ì–‘í•œ í‚¤ ì´ë¦„ ì‹œë„
    let year = null;
    let month = null;

    // ë…„ë„ ì°¾ê¸° - ëª¨ë“  í‚¤ í™•ì¸
    for (const key of Object.keys(row)) {
      const val = row[key];
      if (val && !isNaN(parseInt(String(val)))) {
        const numVal = parseInt(String(val));
        // ì²« ë²ˆì§¸ ìˆ«ì ì»¬ëŸ¼ì´ ë…„ë„ì¼ ê°€ëŠ¥ì„±
        if (key === 'ë…„ë„' || (key.length <= 5 && numVal >= 2000 && numVal <= 2030)) {
          year = numVal;
          break;
        }
      }
    }

    // ì›” ì°¾ê¸°
    for (const key of Object.keys(row)) {
      const val = row[key];
      if (val && !isNaN(parseInt(String(val)))) {
        const numVal = parseInt(String(val));
        if (key === 'ì›”' || (key === Object.keys(row)[1] && numVal >= 1 && numVal <= 12)) {
          month = numVal;
          break;
        }
      }
    }

    // ë…„ë„ì™€ ì›”ì´ ëª¨ë‘ í•„ìš”
    if (!year || !month) {
      continue;
    }

    const dateStr = `${year}-${String(month).padStart(2, '0')}-01`;
    const fileName = path.basename(filePath);

    // ê° êµ¬ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
    for (const [districtName, districtCode] of Object.entries(DISTRICT_CODE_MAP)) {
      const value = row[districtName];
      if (!value && value !== 0) continue;

      // ê°’ ì •ë¦¬ (ë¬¸ìì—´ì¸ ê²½ìš° ì‰¼í‘œ ì œê±°)
      let cleanValue = String(value).replace(/,/g, '').trim();
      cleanValue = cleanValue.replace(/"/g, ''); // ë”°ì˜´í‘œ ì œê±°

      const numValue = parseInt(cleanValue);
      if (isNaN(numValue) || numValue < 0) continue;

      // operation ìƒì„± (SignalHuman ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)
      operations.push({
        updateOne: {
          filter: {
            unit_id: districtCode,
            date: dateStr,
            signal_type: 'total'
          },
          update: {
            $set: {
              unit_id: districtCode,
              date: dateStr,
              signal_type: 'total',
              value: numValue,
              meta: {
                source: 'seoul_district_complaints',
                category: 'complaint',
                district_name: districtName,
                raw_file: fileName,
                aggregation_level: 'district',
                raw: {}
              }
            }
          },
          upsert: true
        }
      });
    }

    processedCount++;
    if (processedCount % 100 === 0) {
      console.log(`  Processed ${processedCount}/${rows.length} rows...`);
    }
  }

  console.log(`  Generated ${operations.length} operations from ${processedCount} rows`);
  return operations;
}

/**
 * ë©”ì¸ í•¨ìˆ˜
 */
async function main() {
  console.log('ğŸš€ Starting ETL pipeline for district-level complaints...\n');
  await connectDB();

  const rawDir = path.join(__dirname, '..', 'data', 'raw');
  
  // íŒŒì¼ íŒ¨í„´ ì§ì ‘ ì§€ì • (ì¸ì½”ë”© ë¬¸ì œ íšŒí”¼)
  const filePatterns = [
    '*ìœ„ì¹˜ë³„*ë¶ˆí¸ì‹ ê³ ê±´ìˆ˜*.csv',
    '*ìœ„ì¹˜ë³„*ë¶ˆí¸ì‹ ê³ ê±´ìˆ˜*.xlsx'
  ];
  
  // globì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì§ì ‘ íŒŒì¼ ì´ë¦„ì„ í™•ì¸
  // list_dir ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ ì´ë¦„ ì§ì ‘ ì§€ì •
  const knownFiles = [
    'ì„œìš¸ì‹œ ìœ„ì¹˜ë³„ ë¶ˆí¸ì‹ ê³ ê±´ìˆ˜ ì •ë³´_2025ë…„_08ì›”.csv',
    'ì„œìš¸ì‹œ ìœ„ì¹˜ë³„ ë¶ˆí¸ì‹ ê³ ê±´ìˆ˜ ì •ë³´_2025ë…„_09ì›”.xlsx',
    'ì„œìš¸ì‹œ ìœ„ì¹˜ë³„ ë¶ˆí¸ì‹ ê³ ê±´ìˆ˜ ì •ë³´_2025ë…„_10ì›”.xlsx',
    'ì„œìš¸ì‹œ ìœ„ì¹˜ë³„ ë¶ˆí¸ì‹ ê³ ê±´ìˆ˜ ì •ë³´_2025ë…„_11ì›”.xlsx',
    'ì„œìš¸ì‹œ ìœ„ì¹˜ë³„ ë¶ˆí¸ì‹ ê³ ê±´ìˆ˜ ì •ë³´_2025ë…„_12ì›” (1).csv'
  ];
  
  // ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§
  const files = knownFiles.filter(f => {
    const filePath = path.join(rawDir, f);
    return fs.existsSync(filePath);
  });
  
  console.log(`\nğŸ“ Found ${files.length} files:\n`);
  files.forEach((file, index) => console.log(`  ${index + 1}. ${file}`));
  console.log('');

  if (files.length === 0) {
    console.log('âš ï¸  No district complaint files found.');
    process.exit(0);
  }

  console.log(`ğŸ“ Found ${files.length} files:\n`);
  files.forEach((file, index) => console.log(`  ${index + 1}. ${file}`));
  console.log('');

  let totalOperations = 0;

  for (const file of files) {
    const filePath = path.join(rawDir, file);

    try {
      let operations;
      if (file.endsWith('.csv')) {
        operations = await processCSV(filePath);
      } else if (file.endsWith('.xlsx')) {
        operations = await processXLSX(filePath);
      } else {
        console.log(`  âš ï¸  Skipping unsupported file: ${file}`);
        continue;
      }

      if (operations.length > 0) {
        // ë°°ì¹˜ë¡œ ì²˜ë¦¬
        const batchSize = 500;
        let bulkProcessedCount = 0;
        let successCount = 0;
        let errorCount = 0;

        for (let i = 0; i < operations.length; i += batchSize) {
          const batch = operations.slice(i, i + batchSize);
          try {
            const result = await SignalHuman.bulkWrite(batch, { ordered: false });
            successCount += result.insertedCount + result.modifiedCount;
            bulkProcessedCount += batch.length;

            if (bulkProcessedCount % 1000 === 0) {
              console.log(`  âœ… Processed ${bulkProcessedCount}/${operations.length} operations...`);
            }
          } catch (error) {
            errorCount += batch.length;
            console.error(`  âŒ Error in batch ${Math.floor(i / batchSize) + 1}:`, error.message);
            // ê°œë³„ ì €ì¥ ì‹œë„
            for (const op of batch) {
              try {
                await SignalHuman.findOneAndUpdate(
                  op.updateOne.filter,
                  op.updateOne.update.$set,
                  { upsert: true, new: true }
                );
                successCount++;
              } catch (err) {
                errorCount++;
              }
            }
          }
        }

        console.log(`  âœ… Imported ${successCount} records from ${file} (errors: ${errorCount})\n`);
        totalOperations += successCount;
      } else {
        console.log(`  âš ï¸  No valid data found in ${file}\n`);
      }
    } catch (error) {
      console.error(`  âŒ Error processing ${file}:`, error.message);
    }
  }

  // ê²°ê³¼ ìš”ì•½
  const count = await SignalHuman.countDocuments({
    'meta.source': 'seoul_district_complaints'
  });
  const distinctDistricts = await SignalHuman.distinct('unit_id', {
    'meta.source': 'seoul_district_complaints'
  });
  const distinctDates = await SignalHuman.distinct('date', {
    'meta.source': 'seoul_district_complaints'
  }).then(dates => dates.sort());

  console.log(`\nâœ… ETL pipeline completed successfully!`);
  console.log(`\nğŸ“Š District-level complaints: ${count.toLocaleString()}ê°œ`);
  console.log(`   ì´ ì²˜ë¦¬ëœ operation ìˆ˜: ${totalOperations}ê°œ`);
  console.log(`   ì§€ì—­ ìˆ˜: ${distinctDistricts.length}ê°œ`);
  console.log(`   ë‚ ì§œ ë²”ìœ„: ${distinctDates[0] || 'ì—†ìŒ'} ~ ${distinctDates[distinctDates.length - 1] || 'ì—†ìŒ'}`);
  console.log(`   ê³ ìœ  ë‚ ì§œ ìˆ˜: ${distinctDates.length}ì¼\n`);

  await mongoose.connection.close();
  process.exit(0);
}

main().catch(error => {
  console.error('âŒ ETL pipeline failed:', error);
  process.exit(1);
});

